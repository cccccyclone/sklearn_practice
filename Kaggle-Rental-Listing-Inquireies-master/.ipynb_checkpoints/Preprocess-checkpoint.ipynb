{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "#-*- encoding: utf-8 -*-\n",
    "import sys\n",
    "import random\n",
    "import operator\n",
    "import datetime\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.metrics import distance as distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_NOT_USE = ['created','description','features','photos', 'index']# ,'bathrooms', 'bedrooms''listing_id',\n",
    "FEATURE_NOT_USE.append('display_address')\n",
    "FEATURE_NOT_USE.extend(['low_build_frac', 'high_build_frac', 'medium_build_frac', 'build_count'])# \n",
    "FEATURE_NOT_USE.extend(['low_manager_frac', 'high_manager_frac', 'medium_manager_frac','manager_count'])#\n",
    "FEATURE_NOT_USE.extend(['Listing_Id', 'img_created']) # , 'time_stamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bedroomProcess(data, train_idx, test_idx):\n",
    "    # Some basic feature from bedrooms\n",
    "    data[\"no_bedroom\"] = data[\"bedrooms\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "    data[\"more_than_5_bedroom\"] = data[\"bedrooms\"].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    data.loc[data[\"bedrooms\"] + data[\"bathrooms\"] == 0, \"bedrooms\"] = 0.001\n",
    "    train = data.iloc[train_idx, :].copy()\n",
    "    test = data.iloc[test_idx, :].copy()\n",
    "    # remove null value (ugly code)\n",
    "    train.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = train[\"bathrooms\"].mean()\n",
    "    test.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = test[\"bathrooms\"].mean()\n",
    "    data.iloc[train_idx, :] = train\n",
    "    data.iloc[test_idx, :] = test\n",
    "    data[\"bedroom_per_room\"] = data[\"bedrooms\"] / (data[\"bedrooms\"] + data[\"bathrooms\"])\n",
    "    data.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = 0\n",
    "    data.loc[data[\"bedrooms\"] == 0.001, \"bedrooms\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bathroomProcess(data, train_idx, test_idx):\n",
    "    # Some basic feature from bathrooms\n",
    "    data.loc[data[\"bathrooms\"] == 112, \"bathrooms\"] = 1.5\n",
    "    data.loc[data[\"bathrooms\"] == 10, \"bathrooms\"] = 1\n",
    "    data.loc[data[\"bathrooms\"] == 20, \"bathrooms\"] = 2\n",
    "    data[\"1_to_2_bathrooms\"] = data[\"bathrooms\"].apply(lambda x : 1if x != 0 and x <= 2 else 0)\n",
    "    data.loc[data[\"bedrooms\"] + data[\"bathrooms\"] == 0, \"bathrooms\"] = 0.001\n",
    "    train = data.iloc[train_idx, :].copy()\n",
    "    test = data.iloc[test_idx, :].copy()\n",
    "    # remove null value (ugly code)\n",
    "    train.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = train[\"bedrooms\"].mean()\n",
    "    test.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = test[\"bedrooms\"].mean()\n",
    "    data.iloc[train_idx, :] = train\n",
    "    data.iloc[test_idx, :] = test\n",
    "    data[\"bathoom_per_room\"] = data[\"bathrooms\"] / (data[\"bedrooms\"] + data[\"bathrooms\"])\n",
    "    data.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = 0\n",
    "    data.loc[data[\"bathrooms\"] == 0.001, \"bathrooms\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildingIdProcess(data, y, train_idx, test_idx):\n",
    "    # Have tried some ideas but failed\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createdProcess(data):\n",
    "    # Some basic features from created\n",
    "    data[\"created\"] = pd.to_datetime(data['created'])\n",
    "    data[\"latest\"] = (data[\"created\"]- data[\"created\"].min())\n",
    "    data[\"latest\"] = data[\"latest\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"passed\"] = (data[\"created\"].max()- data[\"created\"])\n",
    "    data[\"passed\"] = data[\"passed\"].apply(lambda x: x.total_seconds())\n",
    "    # year is weird\n",
    "    data[\"year\"] = data[\"created\"].dt.year\n",
    "    data['month'] = data['created'].dt.month\n",
    "    data['day'] = data['created'].dt.day\n",
    "    data['hour'] = data['created'].dt.hour\n",
    "    data['weekday'] = data['created'].dt.weekday\n",
    "    data['week'] = data['created'].dt.week\n",
    "    data['quarter'] = data['created'].dt.quarter\n",
    "    data['weekend'] = ((data['weekday'] == 5) & (data['weekday'] == 6))\n",
    "    data['weekend'] = data['weekend'].apply(int)\n",
    "    # data[\"created_stamp\"] = data[\"created\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "    #*\n",
    "    data[\"latest_list_rank\"] = data[\"latest\"] / data[\"listing_id\"]   \n",
    "    # data[\"diff_rank_2\"] = data[\"passed\"] / data[\"listing_id\"]\n",
    "    #*\n",
    "\n",
    "    # image time after leak\n",
    "    data.loc[data[\"time_stamp\"] > 1490000000, \"time_stamp\"] = 1478524550\n",
    "    data[\"img_created\"] = data[\"time_stamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    data[\"img_latest\"] = (data[\"img_created\"]- data[\"img_created\"].min())\n",
    "    data[\"img_latest\"] = data[\"img_latest\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"img_passed\"] = (data[\"img_created\"].max()- data[\"img_created\"])\n",
    "    data[\"img_passed\"] = data[\"img_passed\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"img_year\"] = data[\"img_created\"].dt.year\n",
    "    data['img_month'] = data['img_created'].dt.month\n",
    "    data['img_day'] = data['img_created'].dt.day\n",
    "    data['img_hour'] = data['img_created'].dt.hour\n",
    "    # data['img_weekday'] = data['img_created'].dt.weekday\n",
    "    # data['img_week'] = data['img_created'].dt.week\n",
    "    # data['img_quarter'] = data['img_created'].dt.quarter\n",
    "    # data['img_weekend'] = ((data['img_weekday'] == 5) & (data['img_weekday'] == 6))\n",
    "    # data['img_weekend'] = data['img_weekend'].apply(int)\n",
    "    data[\"img_latest_list_rank\"] = data[\"img_latest\"] / data[\"listing_id\"] \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriptionProcess(data, train_idx, test_idx):\n",
    "    data[\"description_words_num\"] = data[\"description\"].apply(lambda x: len(x.split(' ')))\n",
    "    data[\"description_len\"] = data[\"description\"].apply(len)\n",
    "    # Some info from descriptions\n",
    "    desc_feats = {\n",
    "                  'bedroom_mentions': ['br ', '---', \"<a\", \"a>\", \"<p>\"],\n",
    "                  'html_tag_1':[\"<img \", \"</a>\", \"<li>\", \"</li>\", \"<ul>\", \"</ul>\", \"-->\", \"<close\",\"<hr\"],\n",
    "                }\n",
    "    for name, kwords in desc_feats.items():\n",
    "        data[name] =  data['description'].apply(lambda x: sum([x.count(w)  for w in kwords]))\n",
    "\n",
    "    data['description'] =  data['description'].apply(lambda x: str(x).encode('utf-8') if len(x)>2 else \"nulldesc\") \n",
    "    # Tf-idf Encode\n",
    "    tfidfdesc=TfidfVectorizer(min_df=20, max_features=50, strip_accents='unicode',lowercase =True,\n",
    "                        analyzer='word', token_pattern=r'\\w{16,}', ngram_range=(1, 2), use_idf=False,smooth_idf=False, \n",
    "    sublinear_tf=True, stop_words = 'english')  \n",
    "    tr_sparsed = tfidfdesc.fit_transform (data.iloc[train_idx, :][\"description\"])  \n",
    "    te_sparsed = tfidfdesc.transform(data.iloc[test_idx, :][\"description\"])\n",
    "    feats_names = [\"desc_\" + x for x in tfidfdesc.get_feature_names()]\n",
    "    return data, tr_sparsed, te_sparsed, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayAddrProcess(data):\n",
    "    # disp_price_dict = dict(data.groupby('display_address')['price'].mean())\n",
    "    # data[\"mean_disp_price\"] = data.apply(lambda row: disp_price_dict[row[\"display_address\"]], axis=1)\n",
    "    # data[\"addr_sim\"] = data.apply(lambda row: distance.edit_distance(row[\"display_address\"].lower(), row[\"street_address\"].lower()), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featuresProcess(data, train_idx, test_idx):\n",
    "    def afterRemoveStr(l, s):\n",
    "        while s in l:\n",
    "            l.remove(s)\n",
    "        return l\n",
    "\n",
    "    def afterRemoveFirstSpace(l):\n",
    "        res = []\n",
    "        for s in l:\n",
    "            res.append(s.strip())\n",
    "        return res\n",
    "\n",
    "    data[\"features_num\"] = data[\"features\"].apply(len)\n",
    "    mark = \"#+-+#\"\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x]))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: x.lower())\n",
    "\n",
    "    # Deal with list like data\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x.split(\" * \")]))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x.split(\"**\")]))\n",
    "    data['features']=data['features'].str.replace(\"✓ hardwood floor ✓ high ceilings ✓ dishwasher\",\n",
    "        \"hardwood floor\" + mark + \"high ceilings\" + mark + \"dishwasher\")\n",
    "    data['features']=data['features'].str.replace(\n",
    "        \"• on-site lifestyle concierge by luxury attaché \" + \n",
    "        \"•24/7 doorman \" + \n",
    "        \"• state of the art cardiovascular and weight training equipment \" +\n",
    "        \"• 24-hour valet parking garage \" +\n",
    "        \"• valet services including dry cleaning\",\n",
    "        \"on-site lifestyle concierge by luxury attaché\" + mark + \n",
    "        \"24/7 doorman\" + mark + \n",
    "        \"state of the art cardiovascular and weight training equipment\" + mark + \n",
    "        \"24-hour valet parking garage\" + mark + \n",
    "        \"valet services including dry cleaning\")\n",
    "    data['features']=data['features'].str.replace(\n",
    "        '{     0 = \"laundry in unit\";     ' + \n",
    "        '1 = \"cats allowed\";     '+\n",
    "        '10 = hardwood;     '+\n",
    "        '11 = \"high ceilings\";     '+\n",
    "        '12 = renovated;     '+\n",
    "        '13 = \"marble bath\";     '+\n",
    "        '14 = \"granite kitchen\";     '+\n",
    "        '15 = light;     '+\n",
    "        '16 = \"no fee\";     '+\n",
    "        '17 = \"walk-in closet\";     '+\n",
    "        '2 = \"dogs allowed\";     '+\n",
    "        '3 = elevator;     '+\n",
    "        '4 = exclusive;     '+\n",
    "        '6 = laundry;     '+\n",
    "        '7 = subway;     '+\n",
    "        '8 = dishwasher;     '+\n",
    "        '9 = washer; }',\n",
    "        \"laundry in unit\" + mark + \"cats allowed\" + mark + \"hardwood\" + \n",
    "        \"high ceilings\" + mark + \"renovated\" + mark + \"marble bath\" + \n",
    "        \"granite kitchen\" + mark + \"light\" + mark + \"no fee\" +\n",
    "        \"walk-in closet\" + mark + \"dogs allowed\" + mark + \"elevator\" +\n",
    "        \"exclusive\" + mark + \"laundry\" + mark + \"subway\"+\n",
    "        \"dishwasher\" + mark + \"washer\")\n",
    "    data['features']=data['features'].str.replace(\"windowed air-conditioned and monitored laundry room\",\n",
    "        \"windowed air-conditioned\" + mark + \"monitored laundry room\")\n",
    "    data['features']=data['features'].str.replace(\"wall of windows. huge bedrooms\",\n",
    "        \"wall of windows\" + mark + \"huge bedrooms\")\n",
    "    data['features']=data['features'].str.replace(\"to relax and recharge. this spacious 3 bedroom/2 bath residence also features oak hardwood flooring\",\n",
    "        \"spacious\" + mark + \"3 bedroom\" + mark + \"2 bath\" + mark + \"residence\" + mark + \"oak hardwood flooring\")\n",
    "    data['features']=data['features'].str.replace(\"stunning 3 bedroom apartment with a terrace! east harlem! the best deal out now! get it now!!!!\",\n",
    "        \"stunning\" + mark + \"3 bedroom\" + mark + \"a terrace\" + mark + \"east harlem\" + mark + \"the best deal out now! get it now!!!!\")\n",
    "    data['features']=data['features'].str.replace(\"ss appliances - d/w -  m/w - recessed lighting - hardwood floors - high ceilings - marble bath\",\n",
    "        \"ss appliances - d/w -  m/w - \" + mark + \"recessed lighting\" + mark + \"hardwood floors\" + mark + \"high ceilings\" + mark + \"marble bath\")\n",
    "    data['features']=data['features'].str.replace(\"spacious living room for any kind of entertainment. prime location in theater distric\",\n",
    "        \"spacious living room for any kind of entertainment.\" + mark + \"prime location in theater distric\")\n",
    "    data['features']=data['features'].str.replace(\"spacious living room + home office\",\n",
    "        \"spacious living room\" + mark + \"home office\")\n",
    "    data['features']=data['features'].str.replace(\"spacious and sunny 1st floor apartment \"+\n",
    "        \"overlooking the garden  \" + \n",
    "        \"*great williamsburg location*  \"+\n",
    "        \"steps from shopping and cafes \"+\n",
    "        \"and 5 minute walk to graham avenue l train (3rd stop from manhattan)  \"+\n",
    "        \"*shared back yard * \"+\n",
    "        \"large box style rooms * \"+\n",
    "        \"huge living room with high ceilings * \"+\n",
    "        \"nice bathroom with granite floor & ceramic tile * \"+\n",
    "        \"beautiful kitchen with granite counter tops  lots of closet spacehardwood floors *\"+\n",
    "        \" heat included in the rent  \"+\n",
    "        \"clean quiet building   \"+\n",
    "        \"cat ok  \"+\n",
    "        \"great location close to shopping\",\n",
    "        \"spacious\"+ mark +\"sunny 1st floor\"+ mark+ \n",
    "        \"overlooking the garden\" + mark+ \n",
    "        \"great williamsburg location\"+ mark+ \n",
    "        \"steps from shopping and cafes\"+ mark+ \n",
    "        \"5 minute walk to graham avenue\"+ mark +\"train (3rd stop from manhattan)\"+ mark+ \n",
    "        \"shared back yard\"+mark+ \n",
    "        \"large box style rooms\"+mark+ \n",
    "        \"huge living room \" + mark + \"high ceilings\"+ mark+ \n",
    "        \"nice bathroom\" + mark +\"granite floor\" + mark +\"ceramic tile * \"+mark+ \n",
    "        \"beautiful kitchen\" + mark +\"granite counter tops\" + mark +\"closet \" + mark +\"spacehardwood floors\"+mark+ \n",
    "        \"heat included in the rent\"+mark+ \n",
    "        \"clean quiet building\"+mark+ \n",
    "        \"cat ok\"+mark+ \n",
    "        \"close to shopping\")\n",
    "    data['features']=data['features'].str.replace(\"residents-only \" + \n",
    "        \"fitness center \" + \n",
    "        \"and aerobic room \" + \n",
    "        \"professionally outfitted with a full complement of strength and cardio-training equipment\",\n",
    "        \"residents-only\"+ mark +\"itness center\"+ mark+ \n",
    "        \"and aerobic room\" + mark+ \n",
    "        \"cardio-training equipment\")\n",
    "    data['features']=data['features'].str.replace(\"owner occupied - \" + \n",
    "        \"3 family townhouse - \" + \n",
    "        \"no realtor fees -\"+\n",
    "        \" this beautiful apt is offered below market rate\",\n",
    "        \"owner occupied\"+ mark +\"3 family townhouse\"+ mark+ \n",
    "        \"no realtor fees\" + mark+ \n",
    "        \"this beautiful apt is offered below market rate\")\n",
    "    data['features']=data['features'].str.replace(\"newly renovated \"+\n",
    "        \"w/ oak wood floors   \"+\n",
    "        \"mid century modern style interior   \"+\n",
    "        \"large closets in every bedroom \"+\n",
    "        \"extra storage space in hall. \"+\n",
    "        \"large living room\",\n",
    "        \"newly renovated\"+ mark +\"oak wood floors\"+ mark+ \n",
    "        \"mid century modern style interior\" + mark+ \n",
    "        \"large closets in every bedroom\" + mark+ \n",
    "        \"extra storage space in hall\"+ mark +\"large living room\")\n",
    "    data['features']=data['features'].str.replace(\"live-in super package room \"+\n",
    "        \"smoke-free \"+\n",
    "        \"storage available \"+\n",
    "        \"virtual doorman \"+\n",
    "        \"guarantors accepted\",\n",
    "\n",
    "        \"live-in super package room\"+ mark +\"smoke-free\"+ mark+ \n",
    "        \"storage available\" + mark+ \n",
    "        \"virtual doorman\" + mark+ \n",
    "        \"guarantors accepted\")\n",
    "    data['features']=data['features'].str.replace(\"live-in super package room \"+\n",
    "        \"smoke-free \"+\n",
    "        \"storage available \"+\n",
    "        \"virtual doorman \"+\n",
    "        \"guarantors accepted\",\n",
    "\n",
    "        \"live-in super package room\"+ mark +\"smoke-free\"+ mark+ \n",
    "        \"storage available\" + mark+ \n",
    "        \"virtual doorman\" + mark+ \n",
    "        \"guarantors accepted\")\n",
    "\n",
    "    # Merging some features\n",
    "    data['features']=data['features'].str.replace(\"washer/dyer combo\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer inside the unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in-unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in building\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in bldg\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer hookup\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer  stove/oven\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/drier hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/ dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/ dryer hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer-dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer-dryer hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer hookup\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer hook up\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer in the unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer (hookup only)\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer & dryer.\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"wash/dryer\",\"washer/dyer\")\n",
    "\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"pets: cats/small dogs\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets welcome\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets upon approval\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets on approval\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets ok.\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets ok\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets are welcome\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets allowed\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets accepted (on approval)\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet grooming room\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly ( case by case )\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"garden/patio\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"patio\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"residents_garden\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"common garden\",\"garden\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"wifi access\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi included\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi in resident lounge\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi + utilities\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wi fi work lounge\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wi-fi access\",\"wifi\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"24/7\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"24-hour\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"24hr\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"concierge\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"ft doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"24 doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"24 hr doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"doorman service\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"full-time doorman\",\"doorman\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"gym/fitness\",\"fitness\")\n",
    "    data['features']=data['features'].str.replace(\"fitness room\",\"fitness\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"washer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in bldg\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building/dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building_&_dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry room\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry & housekeeping\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in unit\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in-unit\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry on every floor\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry on floor\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"in-unit laundry/dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"on-site laundry\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry/dryer\",\"laundry\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"high-speed internet\",\"high_speed_internet\")\n",
    "    data['features']=data['features'].str.replace(\"high speed internet available\",\"high_speed_internet\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"parking available\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"parking space\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site parking\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site parking lot\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"full service garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"common parking/garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"assigned-parking-space\",\"private_parking\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"storage available\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage facilities available\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage space\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage room\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"common storage\",\"storage\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"central a/c\",\"central_air\")\n",
    "    data['features']=data['features'].str.replace(\"central ac\",\"central_air\")\n",
    "    data['features']=data['features'].str.replace(\"air conditioning\",\"central_air\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"close to  subway\",\"subway\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"roofdeck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof-deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"rooftop terrace\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"rooftop deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof access\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"common roof deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof decks\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof grilling area\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof garden and lounge\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with stunning view\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with real grass\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with grills\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck w/ grills\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck / sun deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck\",\"roof-deck\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"swimming pool\",\"pool\")\n",
    "    data['features']=data['features'].str.replace(\"indoor pool\",\"pool\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"deco fireplace\",\"fireplaces\")\n",
    "    data['features']=data['features'].str.replace(\"decorative fireplace\",\"fireplaces\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"yoga/pilates studio\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga studio\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga room\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga classes\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga and spin studios\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga an pilates class\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga / dance studio\",\"yoga\")\n",
    "\n",
    "\n",
    "    # data[\"features\"] = data[\"features\"].apply(lambda x: afterRemoveStr(x, ''))\n",
    "    # data[\"features\"] = data[\"features\"].apply(lambda x: afterRemoveFirstSpace(x))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: x.split(mark))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "    tfidf = CountVectorizer(stop_words=\"english\", max_features=200)\n",
    "    tr_sparse_feats = tfidf.fit_transform(data.iloc[train_idx, :][\"features\"])\n",
    "    te_sparse_feats = tfidf.transform(data.iloc[test_idx, :][\"features\"])\n",
    "    feats_names = [\"features_\" + x for x in tfidf.get_feature_names()]\n",
    "    return data, tr_sparse_feats, te_sparse_feats, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def locationProcess(data, train_idx, test_idx):\n",
    "    # Clustering\n",
    "\n",
    "    # train_x = data.iloc[train_idx,:][['new_latitude', 'new_longitude']]\n",
    "    # stest_x = data.iloc[test_idx,:][['new_latitude', 'new_longitude']]\n",
    "    train_x = data.iloc[train_idx, :][['latitude', 'longitude']]\n",
    "    test_x = data.iloc[test_idx, :][['latitude', 'longitude']]\n",
    "    kmeans_cluster = KMeans(n_clusters=20)\n",
    "    res = kmeans_cluster.fit(train_x)\n",
    "    res = kmeans_cluster.predict(pd.concat([train_x, test_x]))\n",
    "    d = dict(zip(data['listing_id'], res))\n",
    "    data['cenroid'] = data['listing_id'].apply(lambda x: d[x])\n",
    "    # Manhattan distance\n",
    "    center = [data.iloc[train_idx, :]['latitude'].mean(), data.iloc[train_idx, :]['longitude'].mean()]\n",
    "    data['distance'] = abs(data['latitude'] - center[0]) + abs(data['longitude'] - center[1])\n",
    "    # data['distance_2'] = np.sqrt((data['latitude'] - center[0]) ** 2 + (data['longitude'] - center[1]) ** 2)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def managerIdProcess(data, y, train_idx, test_idx):\n",
    "    manager_lgt_dict = dict(data.groupby('manager_id')['longitude'].mean())\n",
    "    manager_ltt_dict =  dict(data.groupby('manager_id')['latitude'].mean())\n",
    "\n",
    "    # Group manager_id with location info\n",
    "    data[\"mean_man_longitude\"] = data.apply(lambda row: manager_lgt_dict[row[\"manager_id\"]], axis=1)\n",
    "    data[\"mean_man_latitude\"] = data.apply(lambda row: manager_ltt_dict[row[\"manager_id\"]], axis=1)\n",
    "\n",
    "    # Group manager_id with time info\n",
    "    data = group_with_time_features(data, \"manager_id\")\n",
    "    data = group_with_img_time_features(data, \"manager_id\")\n",
    "    manager_stamp_dict = dict(data.groupby('manager_id')['time_stamp'].mean())\n",
    "    data[\"mean_man_timestamp\"] = data.apply(lambda row: manager_stamp_dict[row[\"manager_id\"]], axis=1)\n",
    "    # manager_stamp_dict = dict(data.groupby('manager_id')['created_stamp'].mean())\n",
    "    # data[\"mean_man_createdstamp\"] = data.apply(lambda row: manager_stamp_dict[row[\"manager_id\"]], axis=1)  \n",
    "    return data\n",
    "\n",
    "\n",
    "def photoProcess(data):\n",
    "    data[\"photo_num\"] = data[\"photos\"].apply(len)\n",
    "    return data\n",
    "\n",
    "\n",
    "def priceProcess(data):\n",
    "    #data[\"out_price\"] = data[\"price\"].apply(lambda x: 1 if x < 700 or x > 15000 else 0)\n",
    "    # Clean the outlier\n",
    "    ulimit = 15000#np.percentile(data.price.values, 99)\n",
    "    data.loc[data[\"price\"] > ulimit, \"price\"] = ulimit\n",
    "    dlimit = 350\n",
    "    data.loc[data[\"price\"] < dlimit, \"price\"] = dlimit\n",
    "    data[\"price_per_room\"] = data[\"price\"] / (data[\"bedrooms\"] + data[\"bathrooms\"] + 1.0)\n",
    "    data[\"price_per_bed\"] = data[\"price\"] / (data[\"bedrooms\"] + 1.0)\n",
    "    #*\n",
    "    # data.loc[~np.isfinite(data[\"price_per_room\"]), \"price_per_room\"] = 0\n",
    "    # data.loc[~np.isfinite(data[\"price_per_bed\"]), \"price_per_bed\"] = 0\n",
    "    data[\"price_latitude\"] = data[\"price\"] / (data[\"latitude\"] + 1.0)\n",
    "    data[\"price_longitude\"] = data[\"price\"] / (data[\"longitude\"] + 1.0)\n",
    "\n",
    "    # Grouping price with size or build\n",
    "    median_list = ['bedrooms', 'bathrooms', 'building_id']\n",
    "    # median_list = ['month', 'day', 'hour', 'weekday', 'quarter', 'week', 'passed', 'latest']\n",
    "    for col in median_list:\n",
    "        median_price = data[[col, 'price']].groupby(col)['price'].median()\n",
    "        median_price = median_price[data[col]].values.astype(float)\n",
    "        data['median_' + col] = median_price\n",
    "        data['ratio_' + col] = data['price'] / median_price\n",
    "        data['median_' + col] = data['median_' + col].apply(lambda x: np.log(x))\n",
    "    # data[\"price\"] = data[\"price\"].apply(lambda x: np.log(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def streetAddrProcess(data):\n",
    "    #data[\"new_addr\"] = data[\"street_address\"].apply(lambda x: ' '.join([x.split()[i] for i in range(1, len(x.split()))]))\n",
    "    #data[\"new_addr\"] = preprocessing.LabelEncoder().fit_transform(data[\"new_addr\"])\n",
    "    # data[\"street_address\"] = data[\"street_address\"].apply(lambda x: x.replace('\\u00a0', '').strip().lower)\n",
    "    return data\n",
    "\n",
    "\n",
    "def listingIdProcess(data):\n",
    "    # It's weird。\n",
    "    data[\"listing_id\"] = data[\"listing_id\"] - 68119576.0\n",
    "    return data\n",
    "\n",
    "\n",
    "def coreProcess(data, y_train, train_idx, test_idx):\n",
    "    data = listingIdProcess(data)\n",
    "    data = bedroomProcess(data, train_idx, test_idx)\n",
    "    data = bathroomProcess(data, train_idx, test_idx)\n",
    "    data[\"room_diff\"] = data[\"bathrooms\"] - data[\"bedrooms\"]\n",
    "    data[\"room_num\"] = data[\"bedrooms\"] + data[\"bathrooms\"]\n",
    "    data = createdProcess(data)\n",
    "    data = buildingIdProcess(data, y_train, train_idx, test_idx)\n",
    "    data, tr_sparsed, te_sparsed, feats_sparsed = descriptionProcess(data, train_idx, test_idx)\n",
    "    data = displayAddrProcess(data)\n",
    "    data, tr_sparse, te_sparse, feats_sparse = featuresProcess(data, train_idx, test_idx)\n",
    "    data = locationProcess(data, train_idx, test_idx)\n",
    "    data = managerIdProcess(data, y_train, train_idx, test_idx)\n",
    "    data = photoProcess(data)\n",
    "    data = priceProcess(data)\n",
    "    data = streetAddrProcess(data)\n",
    "    \n",
    "    categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "    for f in categorical:\n",
    "        if data[f].dtype=='object':\n",
    "            cases=defaultdict(int)\n",
    "            temp=np.array(data[f]).tolist()\n",
    "            for k in temp:\n",
    "                cases[k]+=1\n",
    "            # print(f, len(cases))\n",
    "            data[f] = data[f].apply(lambda x: cases[x])\n",
    "            \n",
    "    feats_in_use = [col for col in data.columns if col not in FEATURE_NOT_USE]\n",
    "\n",
    "    data_train = np.array(data.iloc[train_idx, :][feats_in_use])\n",
    "    data_test  = np.array(data.iloc[test_idx, :][feats_in_use])\n",
    "    # Feature Scaling\n",
    "    stda = StandardScaler()  \n",
    "    data_test = stda.fit_transform(data_test)          \n",
    "    data_train = stda.transform(data_train)\n",
    "    #  High cardinality feature\n",
    "    high_card_feats = [\"building_id\", \"manager_id\", \"longitude\", \"room_diff\"] # \"building_id\", \"manager_id\", \n",
    "    # C0 = [3, 12, 0, 4]\n",
    "    C0 = [feats_in_use.index(f) for f in high_card_feats]\n",
    "    W_train, W_cv = convert_to_avg(data_train, y_train, data_test, seed=1, cvals=5, roundings=2, columns=C0)\n",
    "    #  Add Sparse feature\n",
    "    data_train = sparse.hstack([data_train, tr_sparse, tr_sparsed, W_train[:, C0]]).tocsr()\n",
    "    data_test = sparse.hstack([data_test, te_sparse, te_sparsed, W_cv[:, C0]]).tocsr()\n",
    "    feats_in_use.extend(feats_sparse)\n",
    "    feats_in_use.extend(feats_sparsed)\n",
    "    feats_in_use.extend([\"build_high_card\", \"manager_high_card\"])\n",
    "    # print(len(feats_in_use))\n",
    "    # print(tr_sparse.toarray().shape, tr_sparsed.toarray().shape, len(feats_in_use), data_train.shape)\n",
    "    return data_train, data_test, feats_in_use\n",
    "\n",
    "\n",
    "# Copy from KazAnova's starter code\n",
    "def convert_dataset_to_avg(xc,yc,xt, rounding=2,cols=None):\n",
    "    xc = xc.tolist()\n",
    "    xt = xt.tolist()\n",
    "    yc = yc.tolist()\n",
    "    if cols == None:\n",
    "        cols =[k for k in range(0,len(xc[0]))]\n",
    "    woe=[ [0.0 for k in range(0,len(cols))] for g in range(0,len(xt))]\n",
    "    good=[]\n",
    "    bads=[]\n",
    "    for col in cols:\n",
    "        dictsgoouds=defaultdict(int)        \n",
    "        dictsbads=defaultdict(int)\n",
    "        good.append(dictsgoouds)\n",
    "        bads.append(dictsbads)        \n",
    "    total_count=0.0\n",
    "    total_sum =0.0\n",
    "\n",
    "    for a in range (0,len(xc)):\n",
    "        target=yc[a]\n",
    "        total_sum+=target\n",
    "        total_count+=1.0\n",
    "        for j in range(0,len(cols)):\n",
    "            col=cols[j]\n",
    "            good[j][round(xc[a][col],rounding)]+=target\n",
    "            bads[j][round(xc[a][col],rounding)]+=1.0  \n",
    "    #print(total_goods,total_bads)            \n",
    "    \n",
    "    for a in range (0,len(xt)):    \n",
    "        for j in range(0,len(cols)):\n",
    "            col=cols[j]\n",
    "            if round(xt[a][col],rounding) in good[j]:\n",
    "                 woe[a][j]=float(good[j][round(xt[a][col],rounding)])/float(bads[j][round(xt[a][col],rounding)])  \n",
    "            else :\n",
    "                 woe[a][j]=round(total_sum/total_count)\n",
    "    return woe            \n",
    "\n",
    "\n",
    "def convert_to_avg(X,y, Xt, seed=1, cvals=5, roundings=2, columns=None):\n",
    "    \n",
    "    if columns==None:\n",
    "        columns=[k for k in range(0,(X.shape[1]))]    \n",
    "    #print(\"it is not!!\")        \n",
    "    X=X.tolist()\n",
    "    Xt=Xt.tolist() \n",
    "    woetrain=[ [0.0 for k in range(0,len(X[0]))] for g in range(0,len(X))]\n",
    "    woetest=[ [0.0 for k in range(0,len(X[0]))] for g in range(0,len(Xt))]    \n",
    "    \n",
    "    kfolder=StratifiedKFold(y, n_folds=cvals,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kfolder:\n",
    "        # creaning and validation sets\n",
    "        X_train, X_cv = np.array(X)[train_index], np.array(X)[test_index]\n",
    "        y_train = np.array(y)[train_index]\n",
    "\n",
    "        woecv=convert_dataset_to_avg(X_train,y_train,X_cv, rounding=roundings,cols=columns)\n",
    "        X_cv=X_cv.tolist()\n",
    "        no=0\n",
    "        for real_index in test_index:\n",
    "            for j in range(0,len(X_cv[0])):\n",
    "                woetrain[real_index][j]=X_cv[no][j]\n",
    "            no+=1\n",
    "        no=0\n",
    "        for real_index in test_index:\n",
    "            for j in range(0,len(columns)):\n",
    "                col=columns[j]\n",
    "                woetrain[real_index][col]=woecv[no][j]\n",
    "            no+=1      \n",
    "    woefinal=convert_dataset_to_avg(np.array(X),np.array(y),np.array(Xt), rounding=roundings,cols=columns) \n",
    "\n",
    "    for real_index in range(0,len(Xt)):\n",
    "        for j in range(0,len(Xt[0])):           \n",
    "            woetest[real_index][j]=Xt[real_index][j]\n",
    "            \n",
    "    for real_index in range(0,len(Xt)):\n",
    "        for j in range(0,len(columns)):\n",
    "            col=columns[j]\n",
    "            woetest[real_index][col]=woefinal[real_index][j]\n",
    "            \n",
    "    return np.array(woetrain), np.array(woetest)\n",
    "\n",
    "\n",
    "# Grouping (Very important)\n",
    "def group_with_time_features(data, g_feat):\n",
    "    mean_month_dict = dict(data.groupby(g_feat)['month'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_month\"] = data.apply(lambda row: mean_month_dict[row[g_feat]], axis=1)\n",
    "    mean_day_dict = dict(data.groupby(g_feat)['day'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_day\"] = data.apply(lambda row: mean_day_dict[row[g_feat]], axis=1)\n",
    "    mean_hour_dict = dict(data.groupby(g_feat)['hour'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_hour\"] = data.apply(lambda row: mean_hour_dict[row[g_feat]], axis=1)\n",
    "    mean_weekday_dict = dict(data.groupby(g_feat)['weekday'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_weekday\"] = data.apply(lambda row: mean_weekday_dict[row[g_feat]], axis=1)\n",
    "    mean_quarter_dict = dict(data.groupby(g_feat)['quarter'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_quater\"] = data.apply(lambda row: mean_quarter_dict[row[g_feat]], axis=1)\n",
    "    mean_week_dict = dict(data.groupby(g_feat)['week'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_week\"] = data.apply(lambda row: mean_week_dict[row[g_feat]], axis=1)\n",
    "    mean_passed_dict = dict(data.groupby(g_feat)['passed'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_passed\"] = data.apply(lambda row: mean_passed_dict[row[g_feat]], axis=1)\n",
    "    mean_latest_dict = dict(data.groupby(g_feat)['latest'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_latest\"] = data.apply(lambda row: mean_latest_dict[row[g_feat]], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def group_with_img_time_features(data, g_feat):\n",
    "    mean_month_dict = dict(data.groupby(g_feat)['img_month'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_month\"] = data.apply(lambda row: mean_month_dict[row[g_feat]], axis=1)\n",
    "    mean_day_dict = dict(data.groupby(g_feat)['img_day'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_day\"] = data.apply(lambda row: mean_day_dict[row[g_feat]], axis=1)\n",
    "    mean_hour_dict = dict(data.groupby(g_feat)['img_hour'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_hour\"] = data.apply(lambda row: mean_hour_dict[row[g_feat]], axis=1)\n",
    "    # mean_weekday_dict = dict(data.groupby(g_feat)['img_weekday'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_weekday\"] = data.apply(lambda row: mean_weekday_dict[row[g_feat]], axis=1)\n",
    "    # mean_quarter_dict = dict(data.groupby(g_feat)['img_quarter'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_quater\"] = data.apply(lambda row: mean_quarter_dict[row[g_feat]], axis=1)\n",
    "    # mean_week_dict = dict(data.groupby(g_feat)['img_week'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_week\"] = data.apply(lambda row: mean_week_dict[row[g_feat]], axis=1)\n",
    "    mean_passed_dict = dict(data.groupby(g_feat)['img_passed'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_passed\"] = data.apply(lambda row: mean_passed_dict[row[g_feat]], axis=1)\n",
    "    mean_latest_dict = dict(data.groupby(g_feat)['img_latest'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_latest\"] = data.apply(lambda row: mean_latest_dict[row[g_feat]], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "#-*- encoding: utf-8 -*-\n",
    "import sys\n",
    "import random\n",
    "import operator\n",
    "import datetime\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.metrics import distance as distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_NOT_USE = ['created','description','features','photos', 'index']# ,'bathrooms', 'bedrooms''listing_id',\n",
    "FEATURE_NOT_USE.append('display_address')\n",
    "FEATURE_NOT_USE.extend(['low_build_frac', 'high_build_frac', 'medium_build_frac', 'build_count'])# \n",
    "FEATURE_NOT_USE.extend(['low_manager_frac', 'high_manager_frac', 'medium_manager_frac','manager_count'])#\n",
    "FEATURE_NOT_USE.extend(['Listing_Id', 'img_created']) # , 'time_stamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bedroomProcess(data, train_idx, test_idx):\n",
    "    # Some basic feature from bedrooms\n",
    "    data[\"no_bedroom\"] = data[\"bedrooms\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "    data[\"more_than_5_bedroom\"] = data[\"bedrooms\"].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    data.loc[data[\"bedrooms\"] + data[\"bathrooms\"] == 0, \"bedrooms\"] = 0.001\n",
    "    train = data.iloc[train_idx, :].copy()\n",
    "    test = data.iloc[test_idx, :].copy()\n",
    "    # remove null value (ugly code)\n",
    "    train.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = train[\"bathrooms\"].mean()\n",
    "    test.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = test[\"bathrooms\"].mean()\n",
    "    data.iloc[train_idx, :] = train\n",
    "    data.iloc[test_idx, :] = test\n",
    "    data[\"bedroom_per_room\"] = data[\"bedrooms\"] / (data[\"bedrooms\"] + data[\"bathrooms\"])\n",
    "    data.loc[data[\"bedrooms\"] == 0.001, \"bathrooms\"] = 0\n",
    "    data.loc[data[\"bedrooms\"] == 0.001, \"bedrooms\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bathroomProcess(data, train_idx, test_idx):\n",
    "    # Some basic feature from bathrooms\n",
    "    data.loc[data[\"bathrooms\"] == 112, \"bathrooms\"] = 1.5\n",
    "    data.loc[data[\"bathrooms\"] == 10, \"bathrooms\"] = 1\n",
    "    data.loc[data[\"bathrooms\"] == 20, \"bathrooms\"] = 2\n",
    "    data[\"1_to_2_bathrooms\"] = data[\"bathrooms\"].apply(lambda x : 1if x != 0 and x <= 2 else 0)\n",
    "    data.loc[data[\"bedrooms\"] + data[\"bathrooms\"] == 0, \"bathrooms\"] = 0.001\n",
    "    train = data.iloc[train_idx, :].copy()\n",
    "    test = data.iloc[test_idx, :].copy()\n",
    "    # remove null value (ugly code)\n",
    "    train.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = train[\"bedrooms\"].mean()\n",
    "    test.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = test[\"bedrooms\"].mean()\n",
    "    data.iloc[train_idx, :] = train\n",
    "    data.iloc[test_idx, :] = test\n",
    "    data[\"bathoom_per_room\"] = data[\"bathrooms\"] / (data[\"bedrooms\"] + data[\"bathrooms\"])\n",
    "    data.loc[data[\"bathrooms\"] == 0.001, \"bedrooms\"] = 0\n",
    "    data.loc[data[\"bathrooms\"] == 0.001, \"bathrooms\"] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildingIdProcess(data, y, train_idx, test_idx):\n",
    "    # Have tried some ideas but failed\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createdProcess(data):\n",
    "    # Some basic features from created\n",
    "    data[\"created\"] = pd.to_datetime(data['created'])\n",
    "    data[\"latest\"] = (data[\"created\"]- data[\"created\"].min())\n",
    "    data[\"latest\"] = data[\"latest\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"passed\"] = (data[\"created\"].max()- data[\"created\"])\n",
    "    data[\"passed\"] = data[\"passed\"].apply(lambda x: x.total_seconds())\n",
    "    # year is weird\n",
    "    data[\"year\"] = data[\"created\"].dt.year\n",
    "    data['month'] = data['created'].dt.month\n",
    "    data['day'] = data['created'].dt.day\n",
    "    data['hour'] = data['created'].dt.hour\n",
    "    data['weekday'] = data['created'].dt.weekday\n",
    "    data['week'] = data['created'].dt.week\n",
    "    data['quarter'] = data['created'].dt.quarter\n",
    "    data['weekend'] = ((data['weekday'] == 5) & (data['weekday'] == 6))\n",
    "    data['weekend'] = data['weekend'].apply(int)\n",
    "    # data[\"created_stamp\"] = data[\"created\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "    #*\n",
    "    data[\"latest_list_rank\"] = data[\"latest\"] / data[\"listing_id\"]   \n",
    "    # data[\"diff_rank_2\"] = data[\"passed\"] / data[\"listing_id\"]\n",
    "    #*\n",
    "\n",
    "    # image time after leak\n",
    "    data.loc[data[\"time_stamp\"] > 1490000000, \"time_stamp\"] = 1478524550\n",
    "    data[\"img_created\"] = data[\"time_stamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    data[\"img_latest\"] = (data[\"img_created\"]- data[\"img_created\"].min())\n",
    "    data[\"img_latest\"] = data[\"img_latest\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"img_passed\"] = (data[\"img_created\"].max()- data[\"img_created\"])\n",
    "    data[\"img_passed\"] = data[\"img_passed\"].apply(lambda x: x.total_seconds())\n",
    "    data[\"img_year\"] = data[\"img_created\"].dt.year\n",
    "    data['img_month'] = data['img_created'].dt.month\n",
    "    data['img_day'] = data['img_created'].dt.day\n",
    "    data['img_hour'] = data['img_created'].dt.hour\n",
    "    # data['img_weekday'] = data['img_created'].dt.weekday\n",
    "    # data['img_week'] = data['img_created'].dt.week\n",
    "    # data['img_quarter'] = data['img_created'].dt.quarter\n",
    "    # data['img_weekend'] = ((data['img_weekday'] == 5) & (data['img_weekday'] == 6))\n",
    "    # data['img_weekend'] = data['img_weekend'].apply(int)\n",
    "    data[\"img_latest_list_rank\"] = data[\"img_latest\"] / data[\"listing_id\"] \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriptionProcess(data, train_idx, test_idx):\n",
    "    data[\"description_words_num\"] = data[\"description\"].apply(lambda x: len(x.split(' ')))\n",
    "    data[\"description_len\"] = data[\"description\"].apply(len)\n",
    "    # Some info from descriptions\n",
    "    desc_feats = {\n",
    "                  'bedroom_mentions': ['br ', '---', \"<a\", \"a>\", \"<p>\"],\n",
    "                  'html_tag_1':[\"<img \", \"</a>\", \"<li>\", \"</li>\", \"<ul>\", \"</ul>\", \"-->\", \"<close\",\"<hr\"],\n",
    "                }\n",
    "    for name, kwords in desc_feats.items():\n",
    "        data[name] =  data['description'].apply(lambda x: sum([x.count(w)  for w in kwords]))\n",
    "\n",
    "    data['description'] =  data['description'].apply(lambda x: str(x).encode('utf-8') if len(x)>2 else \"nulldesc\") \n",
    "    # Tf-idf Encode\n",
    "    tfidfdesc=TfidfVectorizer(min_df=20, max_features=50, strip_accents='unicode',lowercase =True,\n",
    "                        analyzer='word', token_pattern=r'\\w{16,}', ngram_range=(1, 2), use_idf=False,smooth_idf=False, \n",
    "    sublinear_tf=True, stop_words = 'english')  \n",
    "    tr_sparsed = tfidfdesc.fit_transform (data.iloc[train_idx, :][\"description\"])  \n",
    "    te_sparsed = tfidfdesc.transform(data.iloc[test_idx, :][\"description\"])\n",
    "    feats_names = [\"desc_\" + x for x in tfidfdesc.get_feature_names()]\n",
    "    return data, tr_sparsed, te_sparsed, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayAddrProcess(data):\n",
    "    # disp_price_dict = dict(data.groupby('display_address')['price'].mean())\n",
    "    # data[\"mean_disp_price\"] = data.apply(lambda row: disp_price_dict[row[\"display_address\"]], axis=1)\n",
    "    # data[\"addr_sim\"] = data.apply(lambda row: distance.edit_distance(row[\"display_address\"].lower(), row[\"street_address\"].lower()), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featuresProcess(data, train_idx, test_idx):\n",
    "    def afterRemoveStr(l, s):\n",
    "        while s in l:\n",
    "            l.remove(s)\n",
    "        return l\n",
    "\n",
    "    def afterRemoveFirstSpace(l):\n",
    "        res = []\n",
    "        for s in l:\n",
    "            res.append(s.strip())\n",
    "        return res\n",
    "\n",
    "    data[\"features_num\"] = data[\"features\"].apply(len)\n",
    "    mark = \"#+-+#\"\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x]))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: x.lower())\n",
    "\n",
    "    # Deal with list like data\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x.split(\" * \")]))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: mark.join([i for i in x.split(\"**\")]))\n",
    "    data['features']=data['features'].str.replace(\"✓ hardwood floor ✓ high ceilings ✓ dishwasher\",\n",
    "        \"hardwood floor\" + mark + \"high ceilings\" + mark + \"dishwasher\")\n",
    "    data['features']=data['features'].str.replace(\n",
    "        \"• on-site lifestyle concierge by luxury attaché \" + \n",
    "        \"•24/7 doorman \" + \n",
    "        \"• state of the art cardiovascular and weight training equipment \" +\n",
    "        \"• 24-hour valet parking garage \" +\n",
    "        \"• valet services including dry cleaning\",\n",
    "        \"on-site lifestyle concierge by luxury attaché\" + mark + \n",
    "        \"24/7 doorman\" + mark + \n",
    "        \"state of the art cardiovascular and weight training equipment\" + mark + \n",
    "        \"24-hour valet parking garage\" + mark + \n",
    "        \"valet services including dry cleaning\")\n",
    "    data['features']=data['features'].str.replace(\n",
    "        '{     0 = \"laundry in unit\";     ' + \n",
    "        '1 = \"cats allowed\";     '+\n",
    "        '10 = hardwood;     '+\n",
    "        '11 = \"high ceilings\";     '+\n",
    "        '12 = renovated;     '+\n",
    "        '13 = \"marble bath\";     '+\n",
    "        '14 = \"granite kitchen\";     '+\n",
    "        '15 = light;     '+\n",
    "        '16 = \"no fee\";     '+\n",
    "        '17 = \"walk-in closet\";     '+\n",
    "        '2 = \"dogs allowed\";     '+\n",
    "        '3 = elevator;     '+\n",
    "        '4 = exclusive;     '+\n",
    "        '6 = laundry;     '+\n",
    "        '7 = subway;     '+\n",
    "        '8 = dishwasher;     '+\n",
    "        '9 = washer; }',\n",
    "        \"laundry in unit\" + mark + \"cats allowed\" + mark + \"hardwood\" + \n",
    "        \"high ceilings\" + mark + \"renovated\" + mark + \"marble bath\" + \n",
    "        \"granite kitchen\" + mark + \"light\" + mark + \"no fee\" +\n",
    "        \"walk-in closet\" + mark + \"dogs allowed\" + mark + \"elevator\" +\n",
    "        \"exclusive\" + mark + \"laundry\" + mark + \"subway\"+\n",
    "        \"dishwasher\" + mark + \"washer\")\n",
    "    data['features']=data['features'].str.replace(\"windowed air-conditioned and monitored laundry room\",\n",
    "        \"windowed air-conditioned\" + mark + \"monitored laundry room\")\n",
    "    data['features']=data['features'].str.replace(\"wall of windows. huge bedrooms\",\n",
    "        \"wall of windows\" + mark + \"huge bedrooms\")\n",
    "    data['features']=data['features'].str.replace(\"to relax and recharge. this spacious 3 bedroom/2 bath residence also features oak hardwood flooring\",\n",
    "        \"spacious\" + mark + \"3 bedroom\" + mark + \"2 bath\" + mark + \"residence\" + mark + \"oak hardwood flooring\")\n",
    "    data['features']=data['features'].str.replace(\"stunning 3 bedroom apartment with a terrace! east harlem! the best deal out now! get it now!!!!\",\n",
    "        \"stunning\" + mark + \"3 bedroom\" + mark + \"a terrace\" + mark + \"east harlem\" + mark + \"the best deal out now! get it now!!!!\")\n",
    "    data['features']=data['features'].str.replace(\"ss appliances - d/w -  m/w - recessed lighting - hardwood floors - high ceilings - marble bath\",\n",
    "        \"ss appliances - d/w -  m/w - \" + mark + \"recessed lighting\" + mark + \"hardwood floors\" + mark + \"high ceilings\" + mark + \"marble bath\")\n",
    "    data['features']=data['features'].str.replace(\"spacious living room for any kind of entertainment. prime location in theater distric\",\n",
    "        \"spacious living room for any kind of entertainment.\" + mark + \"prime location in theater distric\")\n",
    "    data['features']=data['features'].str.replace(\"spacious living room + home office\",\n",
    "        \"spacious living room\" + mark + \"home office\")\n",
    "    data['features']=data['features'].str.replace(\"spacious and sunny 1st floor apartment \"+\n",
    "        \"overlooking the garden  \" + \n",
    "        \"*great williamsburg location*  \"+\n",
    "        \"steps from shopping and cafes \"+\n",
    "        \"and 5 minute walk to graham avenue l train (3rd stop from manhattan)  \"+\n",
    "        \"*shared back yard * \"+\n",
    "        \"large box style rooms * \"+\n",
    "        \"huge living room with high ceilings * \"+\n",
    "        \"nice bathroom with granite floor & ceramic tile * \"+\n",
    "        \"beautiful kitchen with granite counter tops  lots of closet spacehardwood floors *\"+\n",
    "        \" heat included in the rent  \"+\n",
    "        \"clean quiet building   \"+\n",
    "        \"cat ok  \"+\n",
    "        \"great location close to shopping\",\n",
    "        \"spacious\"+ mark +\"sunny 1st floor\"+ mark+ \n",
    "        \"overlooking the garden\" + mark+ \n",
    "        \"great williamsburg location\"+ mark+ \n",
    "        \"steps from shopping and cafes\"+ mark+ \n",
    "        \"5 minute walk to graham avenue\"+ mark +\"train (3rd stop from manhattan)\"+ mark+ \n",
    "        \"shared back yard\"+mark+ \n",
    "        \"large box style rooms\"+mark+ \n",
    "        \"huge living room \" + mark + \"high ceilings\"+ mark+ \n",
    "        \"nice bathroom\" + mark +\"granite floor\" + mark +\"ceramic tile * \"+mark+ \n",
    "        \"beautiful kitchen\" + mark +\"granite counter tops\" + mark +\"closet \" + mark +\"spacehardwood floors\"+mark+ \n",
    "        \"heat included in the rent\"+mark+ \n",
    "        \"clean quiet building\"+mark+ \n",
    "        \"cat ok\"+mark+ \n",
    "        \"close to shopping\")\n",
    "    data['features']=data['features'].str.replace(\"residents-only \" + \n",
    "        \"fitness center \" + \n",
    "        \"and aerobic room \" + \n",
    "        \"professionally outfitted with a full complement of strength and cardio-training equipment\",\n",
    "        \"residents-only\"+ mark +\"itness center\"+ mark+ \n",
    "        \"and aerobic room\" + mark+ \n",
    "        \"cardio-training equipment\")\n",
    "    data['features']=data['features'].str.replace(\"owner occupied - \" + \n",
    "        \"3 family townhouse - \" + \n",
    "        \"no realtor fees -\"+\n",
    "        \" this beautiful apt is offered below market rate\",\n",
    "        \"owner occupied\"+ mark +\"3 family townhouse\"+ mark+ \n",
    "        \"no realtor fees\" + mark+ \n",
    "        \"this beautiful apt is offered below market rate\")\n",
    "    data['features']=data['features'].str.replace(\"newly renovated \"+\n",
    "        \"w/ oak wood floors   \"+\n",
    "        \"mid century modern style interior   \"+\n",
    "        \"large closets in every bedroom \"+\n",
    "        \"extra storage space in hall. \"+\n",
    "        \"large living room\",\n",
    "        \"newly renovated\"+ mark +\"oak wood floors\"+ mark+ \n",
    "        \"mid century modern style interior\" + mark+ \n",
    "        \"large closets in every bedroom\" + mark+ \n",
    "        \"extra storage space in hall\"+ mark +\"large living room\")\n",
    "    data['features']=data['features'].str.replace(\"live-in super package room \"+\n",
    "        \"smoke-free \"+\n",
    "        \"storage available \"+\n",
    "        \"virtual doorman \"+\n",
    "        \"guarantors accepted\",\n",
    "\n",
    "        \"live-in super package room\"+ mark +\"smoke-free\"+ mark+ \n",
    "        \"storage available\" + mark+ \n",
    "        \"virtual doorman\" + mark+ \n",
    "        \"guarantors accepted\")\n",
    "    data['features']=data['features'].str.replace(\"live-in super package room \"+\n",
    "        \"smoke-free \"+\n",
    "        \"storage available \"+\n",
    "        \"virtual doorman \"+\n",
    "        \"guarantors accepted\",\n",
    "\n",
    "        \"live-in super package room\"+ mark +\"smoke-free\"+ mark+ \n",
    "        \"storage available\" + mark+ \n",
    "        \"virtual doorman\" + mark+ \n",
    "        \"guarantors accepted\")\n",
    "\n",
    "    # Merging some features\n",
    "    data['features']=data['features'].str.replace(\"washer/dyer combo\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer inside the unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in-unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in building\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer in bldg\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer hookup\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/dryer  stove/oven\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/drier hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/ dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer/ dryer hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer-dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer-dryer hookups\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer hookup\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer dryer hook up\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer in the unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer and dryer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer in unit\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer (hookup only)\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer / dryer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer & dryer.\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"washer\",\"washer/dyer\")\n",
    "    data['features']=data['features'].str.replace(\"wash/dryer\",\"washer/dyer\")\n",
    "\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"pets: cats/small dogs\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets welcome\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets upon approval\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets on approval\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets ok.\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets ok\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets are welcome\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets allowed\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets accepted (on approval)\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pets\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet grooming room\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly ( case by case )\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "    data['features']=data['features'].str.replace(\"pet friendly building\",\"pet-friendly\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"garden/patio\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"patio\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"residents_garden\",\"garden\")\n",
    "    data['features']=data['features'].str.replace(\"common garden\",\"garden\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"wifi access\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi included\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi in resident lounge\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wifi + utilities\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wi fi work lounge\",\"wifi\")\n",
    "    data['features']=data['features'].str.replace(\"wi-fi access\",\"wifi\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"24/7\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"24-hour\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"24hr\",\"24\")\n",
    "    data['features']=data['features'].str.replace(\"concierge\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"ft doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"24 doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"24 hr doorman\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"doorman service\",\"doorman\")\n",
    "    data['features']=data['features'].str.replace(\"full-time doorman\",\"doorman\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"gym/fitness\",\"fitness\")\n",
    "    data['features']=data['features'].str.replace(\"fitness room\",\"fitness\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"washer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in bldg\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building/dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in building_&_dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry room\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry & housekeeping\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in unit\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry in-unit\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry on every floor\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry on floor\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"in-unit laundry/dryer\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"on-site laundry\",\"laundry\")\n",
    "    data['features']=data['features'].str.replace(\"laundry/dryer\",\"laundry\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"high-speed internet\",\"high_speed_internet\")\n",
    "    data['features']=data['features'].str.replace(\"high speed internet available\",\"high_speed_internet\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"parking available\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"parking space\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site parking\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"on-site parking lot\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"full service garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"common parking/garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"garage\",\"parking\")\n",
    "    data['features']=data['features'].str.replace(\"assigned-parking-space\",\"private_parking\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"storage available\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage facilities available\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage space\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"storage room\",\"storage\")\n",
    "    data['features']=data['features'].str.replace(\"common storage\",\"storage\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"central a/c\",\"central_air\")\n",
    "    data['features']=data['features'].str.replace(\"central ac\",\"central_air\")\n",
    "    data['features']=data['features'].str.replace(\"air conditioning\",\"central_air\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"close to  subway\",\"subway\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"roofdeck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof-deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"rooftop terrace\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"rooftop deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof access\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"common roof deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof decks\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof grilling area\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof garden and lounge\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with stunning view\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with real grass\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck with grills\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck w/ grills\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck / sun deck\",\"roof-deck\")\n",
    "    data['features']=data['features'].str.replace(\"roof deck\",\"roof-deck\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"swimming pool\",\"pool\")\n",
    "    data['features']=data['features'].str.replace(\"indoor pool\",\"pool\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"deco fireplace\",\"fireplaces\")\n",
    "    data['features']=data['features'].str.replace(\"decorative fireplace\",\"fireplaces\")\n",
    "\n",
    "    data['features']=data['features'].str.replace(\"yoga/pilates studio\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga studio\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga room\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga classes\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga and spin studios\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga an pilates class\",\"yoga\")\n",
    "    data['features']=data['features'].str.replace(\"yoga / dance studio\",\"yoga\")\n",
    "\n",
    "\n",
    "    # data[\"features\"] = data[\"features\"].apply(lambda x: afterRemoveStr(x, ''))\n",
    "    # data[\"features\"] = data[\"features\"].apply(lambda x: afterRemoveFirstSpace(x))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: x.split(mark))\n",
    "    data[\"features\"] = data[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "    tfidf = CountVectorizer(stop_words=\"english\", max_features=200)\n",
    "    tr_sparse_feats = tfidf.fit_transform(data.iloc[train_idx, :][\"features\"])\n",
    "    te_sparse_feats = tfidf.transform(data.iloc[test_idx, :][\"features\"])\n",
    "    feats_names = [\"features_\" + x for x in tfidf.get_feature_names()]\n",
    "    return data, tr_sparse_feats, te_sparse_feats, feats_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def locationProcess(data, train_idx, test_idx):\n",
    "    # Clustering\n",
    "\n",
    "    # train_x = data.iloc[train_idx,:][['new_latitude', 'new_longitude']]\n",
    "    # stest_x = data.iloc[test_idx,:][['new_latitude', 'new_longitude']]\n",
    "    train_x = data.iloc[train_idx, :][['latitude', 'longitude']]\n",
    "    test_x = data.iloc[test_idx, :][['latitude', 'longitude']]\n",
    "    kmeans_cluster = KMeans(n_clusters=20)\n",
    "    res = kmeans_cluster.fit(train_x)\n",
    "    res = kmeans_cluster.predict(pd.concat([train_x, test_x]))\n",
    "    d = dict(zip(data['listing_id'], res))\n",
    "    data['cenroid'] = data['listing_id'].apply(lambda x: d[x])\n",
    "    # Manhattan distance\n",
    "    center = [data.iloc[train_idx, :]['latitude'].mean(), data.iloc[train_idx, :]['longitude'].mean()]\n",
    "    data['distance'] = abs(data['latitude'] - center[0]) + abs(data['longitude'] - center[1])\n",
    "    # data['distance_2'] = np.sqrt((data['latitude'] - center[0]) ** 2 + (data['longitude'] - center[1]) ** 2)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def managerIdProcess(data, y, train_idx, test_idx):\n",
    "    manager_lgt_dict = dict(data.groupby('manager_id')['longitude'].mean())\n",
    "    manager_ltt_dict =  dict(data.groupby('manager_id')['latitude'].mean())\n",
    "\n",
    "    # Group manager_id with location info\n",
    "    data[\"mean_man_longitude\"] = data.apply(lambda row: manager_lgt_dict[row[\"manager_id\"]], axis=1)\n",
    "    data[\"mean_man_latitude\"] = data.apply(lambda row: manager_ltt_dict[row[\"manager_id\"]], axis=1)\n",
    "\n",
    "    # Group manager_id with time info\n",
    "    data = group_with_time_features(data, \"manager_id\")\n",
    "    data = group_with_img_time_features(data, \"manager_id\")\n",
    "    manager_stamp_dict = dict(data.groupby('manager_id')['time_stamp'].mean())\n",
    "    data[\"mean_man_timestamp\"] = data.apply(lambda row: manager_stamp_dict[row[\"manager_id\"]], axis=1)\n",
    "    # manager_stamp_dict = dict(data.groupby('manager_id')['created_stamp'].mean())\n",
    "    # data[\"mean_man_createdstamp\"] = data.apply(lambda row: manager_stamp_dict[row[\"manager_id\"]], axis=1)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def photoProcess(data):\n",
    "    data[\"photo_num\"] = data[\"photos\"].apply(len)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def priceProcess(data):\n",
    "    #data[\"out_price\"] = data[\"price\"].apply(lambda x: 1 if x < 700 or x > 15000 else 0)\n",
    "    # Clean the outlier\n",
    "    ulimit = 15000#np.percentile(data.price.values, 99)\n",
    "    data.loc[data[\"price\"] > ulimit, \"price\"] = ulimit\n",
    "    dlimit = 350\n",
    "    data.loc[data[\"price\"] < dlimit, \"price\"] = dlimit\n",
    "    data[\"price_per_room\"] = data[\"price\"] / (data[\"bedrooms\"] + data[\"bathrooms\"] + 1.0)\n",
    "    data[\"price_per_bed\"] = data[\"price\"] / (data[\"bedrooms\"] + 1.0)\n",
    "    #*\n",
    "    # data.loc[~np.isfinite(data[\"price_per_room\"]), \"price_per_room\"] = 0\n",
    "    # data.loc[~np.isfinite(data[\"price_per_bed\"]), \"price_per_bed\"] = 0\n",
    "    data[\"price_latitude\"] = data[\"price\"] / (data[\"latitude\"] + 1.0)\n",
    "    data[\"price_longitude\"] = data[\"price\"] / (data[\"longitude\"] + 1.0)\n",
    "\n",
    "    # Grouping price with size or build\n",
    "    median_list = ['bedrooms', 'bathrooms', 'building_id']\n",
    "    # median_list = ['month', 'day', 'hour', 'weekday', 'quarter', 'week', 'passed', 'latest']\n",
    "    for col in median_list:\n",
    "        median_price = data[[col, 'price']].groupby(col)['price'].median()\n",
    "        median_price = median_price[data[col]].values.astype(float)\n",
    "        data['median_' + col] = median_price\n",
    "        data['ratio_' + col] = data['price'] / median_price\n",
    "        data['median_' + col] = data['median_' + col].apply(lambda x: np.log(x))\n",
    "    # data[\"price\"] = data[\"price\"].apply(lambda x: np.log(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def streetAddrProcess(data):\n",
    "    #data[\"new_addr\"] = data[\"street_address\"].apply(lambda x: ' '.join([x.split()[i] for i in range(1, len(x.split()))]))\n",
    "    #data[\"new_addr\"] = preprocessing.LabelEncoder().fit_transform(data[\"new_addr\"])\n",
    "    # data[\"street_address\"] = data[\"street_address\"].apply(lambda x: x.replace('\\u00a0', '').strip().lower)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listingIdProcess(data):\n",
    "    # It's weird。\n",
    "    data[\"listing_id\"] = data[\"listing_id\"] - 68119576.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coreProcess(data, y_train, train_idx, test_idx):\n",
    "    data = listingIdProcess(data)\n",
    "    data = bedroomProcess(data, train_idx, test_idx)\n",
    "    data = bathroomProcess(data, train_idx, test_idx)\n",
    "    data[\"room_diff\"] = data[\"bathrooms\"] - data[\"bedrooms\"]\n",
    "    data[\"room_num\"] = data[\"bedrooms\"] + data[\"bathrooms\"]\n",
    "    data = createdProcess(data)\n",
    "    data = buildingIdProcess(data, y_train, train_idx, test_idx)\n",
    "    data, tr_sparsed, te_sparsed, feats_sparsed = descriptionProcess(data, train_idx, test_idx)\n",
    "    data = displayAddrProcess(data)\n",
    "    data, tr_sparse, te_sparse, feats_sparse = featuresProcess(data, train_idx, test_idx)\n",
    "    data = locationProcess(data, train_idx, test_idx)\n",
    "    data = managerIdProcess(data, y_train, train_idx, test_idx)\n",
    "    data = photoProcess(data)\n",
    "    data = priceProcess(data)\n",
    "    data = streetAddrProcess(data)\n",
    "    \n",
    "    categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "    for f in categorical:\n",
    "        if data[f].dtype=='object':\n",
    "            cases=defaultdict(int)\n",
    "            temp=np.array(data[f]).tolist()\n",
    "            for k in temp:\n",
    "                cases[k]+=1\n",
    "            # print(f, len(cases))\n",
    "            data[f] = data[f].apply(lambda x: cases[x])\n",
    "            \n",
    "    feats_in_use = [col for col in data.columns if col not in FEATURE_NOT_USE]\n",
    "\n",
    "    data_train = np.array(data.iloc[train_idx, :][feats_in_use])\n",
    "    data_test  = np.array(data.iloc[test_idx, :][feats_in_use])\n",
    "    # Feature Scaling\n",
    "    stda = StandardScaler()  \n",
    "    data_test = stda.fit_transform(data_test)          \n",
    "    data_train = stda.transform(data_train)\n",
    "    #  High cardinality feature\n",
    "    high_card_feats = [\"building_id\", \"manager_id\", \"longitude\", \"room_diff\"] # \"building_id\", \"manager_id\", \n",
    "    # C0 = [3, 12, 0, 4]\n",
    "    C0 = [feats_in_use.index(f) for f in high_card_feats]\n",
    "    W_train, W_cv = convert_to_avg(data_train, y_train, data_test, seed=1, cvals=5, roundings=2, columns=C0)\n",
    "    #  Add Sparse feature\n",
    "    data_train = sparse.hstack([data_train, tr_sparse, tr_sparsed, W_train[:, C0]]).tocsr()\n",
    "    data_test = sparse.hstack([data_test, te_sparse, te_sparsed, W_cv[:, C0]]).tocsr()\n",
    "    feats_in_use.extend(feats_sparse)\n",
    "    feats_in_use.extend(feats_sparsed)\n",
    "    feats_in_use.extend([\"build_high_card\", \"manager_high_card\"])\n",
    "    # print(len(feats_in_use))\n",
    "    # print(tr_sparse.toarray().shape, tr_sparsed.toarray().shape, len(feats_in_use), data_train.shape)\n",
    "    return data_train, data_test, feats_in_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy from KazAnova's starter code\n",
    "def convert_dataset_to_avg(xc,yc,xt, rounding=2,cols=None):\n",
    "    xc = xc.tolist()\n",
    "    xt = xt.tolist()\n",
    "    yc = yc.tolist()\n",
    "    if cols == None:\n",
    "        cols =[k for k in range(0,len(xc[0]))]\n",
    "    woe=[ [0.0 for k in range(0,len(cols))] for g in range(0,len(xt))]\n",
    "    good=[]\n",
    "    bads=[]\n",
    "    for col in cols:\n",
    "        dictsgoouds=defaultdict(int)        \n",
    "        dictsbads=defaultdict(int)\n",
    "        good.append(dictsgoouds)\n",
    "        bads.append(dictsbads)        \n",
    "    total_count=0.0\n",
    "    total_sum =0.0\n",
    "\n",
    "    for a in range (0,len(xc)):\n",
    "        target=yc[a]\n",
    "        total_sum+=target\n",
    "        total_count+=1.0\n",
    "        for j in range(0,len(cols)):\n",
    "            col=cols[j]\n",
    "            good[j][round(xc[a][col],rounding)]+=target\n",
    "            bads[j][round(xc[a][col],rounding)]+=1.0  \n",
    "    #print(total_goods,total_bads)            \n",
    "    \n",
    "    for a in range (0,len(xt)):    \n",
    "        for j in range(0,len(cols)):\n",
    "            col=cols[j]\n",
    "            if round(xt[a][col],rounding) in good[j]:\n",
    "                 woe[a][j]=float(good[j][round(xt[a][col],rounding)])/float(bads[j][round(xt[a][col],rounding)])  \n",
    "            else :\n",
    "                 woe[a][j]=round(total_sum/total_count)\n",
    "    return woe            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_avg(X,y, Xt, seed=1, cvals=5, roundings=2, columns=None):\n",
    "    \n",
    "    if columns==None:\n",
    "        columns=[k for k in range(0,(X.shape[1]))]    \n",
    "    #print(\"it is not!!\")        \n",
    "    X=X.tolist()\n",
    "    Xt=Xt.tolist() \n",
    "    woetrain=[ [0.0 for k in range(0,len(X[0]))] for g in range(0,len(X))]\n",
    "    woetest=[ [0.0 for k in range(0,len(X[0]))] for g in range(0,len(Xt))]    \n",
    "    \n",
    "    kfolder=StratifiedKFold(y, n_folds=cvals,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kfolder:\n",
    "        # creaning and validation sets\n",
    "        X_train, X_cv = np.array(X)[train_index], np.array(X)[test_index]\n",
    "        y_train = np.array(y)[train_index]\n",
    "\n",
    "        woecv=convert_dataset_to_avg(X_train,y_train,X_cv, rounding=roundings,cols=columns)\n",
    "        X_cv=X_cv.tolist()\n",
    "        no=0\n",
    "        for real_index in test_index:\n",
    "            for j in range(0,len(X_cv[0])):\n",
    "                woetrain[real_index][j]=X_cv[no][j]\n",
    "            no+=1\n",
    "        no=0\n",
    "        for real_index in test_index:\n",
    "            for j in range(0,len(columns)):\n",
    "                col=columns[j]\n",
    "                woetrain[real_index][col]=woecv[no][j]\n",
    "            no+=1      \n",
    "    woefinal=convert_dataset_to_avg(np.array(X),np.array(y),np.array(Xt), rounding=roundings,cols=columns) \n",
    "\n",
    "    for real_index in range(0,len(Xt)):\n",
    "        for j in range(0,len(Xt[0])):           \n",
    "            woetest[real_index][j]=Xt[real_index][j]\n",
    "            \n",
    "    for real_index in range(0,len(Xt)):\n",
    "        for j in range(0,len(columns)):\n",
    "            col=columns[j]\n",
    "            woetest[real_index][col]=woefinal[real_index][j]\n",
    "            \n",
    "    return np.array(woetrain), np.array(woetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping (Very important)\n",
    "def group_with_time_features(data, g_feat):\n",
    "    mean_month_dict = dict(data.groupby(g_feat)['month'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_month\"] = data.apply(lambda row: mean_month_dict[row[g_feat]], axis=1)\n",
    "    mean_day_dict = dict(data.groupby(g_feat)['day'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_day\"] = data.apply(lambda row: mean_day_dict[row[g_feat]], axis=1)\n",
    "    mean_hour_dict = dict(data.groupby(g_feat)['hour'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_hour\"] = data.apply(lambda row: mean_hour_dict[row[g_feat]], axis=1)\n",
    "    mean_weekday_dict = dict(data.groupby(g_feat)['weekday'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_weekday\"] = data.apply(lambda row: mean_weekday_dict[row[g_feat]], axis=1)\n",
    "    mean_quarter_dict = dict(data.groupby(g_feat)['quarter'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_quater\"] = data.apply(lambda row: mean_quarter_dict[row[g_feat]], axis=1)\n",
    "    mean_week_dict = dict(data.groupby(g_feat)['week'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_week\"] = data.apply(lambda row: mean_week_dict[row[g_feat]], axis=1)\n",
    "    mean_passed_dict = dict(data.groupby(g_feat)['passed'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_passed\"] = data.apply(lambda row: mean_passed_dict[row[g_feat]], axis=1)\n",
    "    mean_latest_dict = dict(data.groupby(g_feat)['latest'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_latest\"] = data.apply(lambda row: mean_latest_dict[row[g_feat]], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_with_img_time_features(data, g_feat):\n",
    "    mean_month_dict = dict(data.groupby(g_feat)['img_month'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_month\"] = data.apply(lambda row: mean_month_dict[row[g_feat]], axis=1)\n",
    "    mean_day_dict = dict(data.groupby(g_feat)['img_day'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_day\"] = data.apply(lambda row: mean_day_dict[row[g_feat]], axis=1)\n",
    "    mean_hour_dict = dict(data.groupby(g_feat)['img_hour'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_hour\"] = data.apply(lambda row: mean_hour_dict[row[g_feat]], axis=1)\n",
    "    # mean_weekday_dict = dict(data.groupby(g_feat)['img_weekday'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_weekday\"] = data.apply(lambda row: mean_weekday_dict[row[g_feat]], axis=1)\n",
    "    # mean_quarter_dict = dict(data.groupby(g_feat)['img_quarter'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_quater\"] = data.apply(lambda row: mean_quarter_dict[row[g_feat]], axis=1)\n",
    "    # mean_week_dict = dict(data.groupby(g_feat)['img_week'].mean())\n",
    "    # data[\"mean_\" + g_feat + \"_img_week\"] = data.apply(lambda row: mean_week_dict[row[g_feat]], axis=1)\n",
    "    mean_passed_dict = dict(data.groupby(g_feat)['img_passed'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_passed\"] = data.apply(lambda row: mean_passed_dict[row[g_feat]], axis=1)\n",
    "    mean_latest_dict = dict(data.groupby(g_feat)['img_latest'].mean())\n",
    "    data[\"mean_\" + g_feat + \"_img_latest\"] = data.apply(lambda row: mean_latest_dict[row[g_feat]], axis=1)\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
