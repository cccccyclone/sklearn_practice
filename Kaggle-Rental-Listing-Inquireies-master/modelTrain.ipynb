{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from preprocess import coreProcess\n",
    "from classifiers import xgboostClassifier\n",
    "\n",
    "TRAIN_FILE_NAME = '~/Kaggle/RLI/input/train.json'\n",
    "TEST_FILE_NAME = '~/Kaggle/RLI/input/test.json'\n",
    "target_num_map = {'high': 0, 'medium': 1, 'low': 2}\n",
    "train_data = pd.read_json(TRAIN_FILE_NAME).reset_index()\n",
    "test_data = pd.read_json(TEST_FILE_NAME).reset_index()\n",
    "list_img_time = pd.read_csv(\"~/Kaggle/RLI/input/listing_image_time.csv\")\n",
    "train_data = train_data.merge(list_img_time, left_on=\"listing_id\", right_on=\"Listing_Id\", how='inner')\n",
    "test_data = test_data.merge(list_img_time, left_on=\"listing_id\", right_on=\"Listing_Id\", how='inner')\n",
    "RS = 2016\n",
    "random.seed(RS)\n",
    "np.random.seed(RS)\n",
    "# RS = 0\n",
    "\n",
    "def validation_score(early_stop=False):\n",
    "    clf = xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 3,\n",
    "        eta = 0.04,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.7,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.7,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 700,\n",
    "        seed = RS,\n",
    "    )\n",
    "    print(\"*** Validation start ***\")\n",
    "    data = train_data.copy()\n",
    "    y = data[\"interest_level\"].apply(lambda x: target_num_map[x])\n",
    "    del data[\"interest_level\"]\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=5, random_state=RS, shuffle=True)\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "    cv_scores = []\n",
    "    i = 0\n",
    "    for train_idx, val_idx in skf.split(data, y):\n",
    "        i += 1\n",
    "        X = data.copy()\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        X_train, X_val, feats = coreProcess(X, y_train, train_idx, val_idx)\n",
    "        clf.fit(X_train, y_train)\n",
    "        # clf.fit_CV(X_train, X_val, y_train, y_val)\n",
    "        y_val_pred = clf.predict_proba(X_val)\n",
    "        loss = log_loss(y_val, y_val_pred)\n",
    "        print(\"Iteration {}'s loss: {}\".format(i, loss))\n",
    "        cv_scores.append(loss)\n",
    "        if early_stop:\n",
    "            break\n",
    "    print(\"*** Validation finished ***\\n\")\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "def validation_avg_score(clfs):\n",
    "    print(\"*** Validation start ***\")\n",
    "    data = train_data.copy()\n",
    "    y = data[\"interest_level\"].apply(lambda x: target_num_map[x])\n",
    "    del data[\"interest_level\"]\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=5, random_state=RS, shuffle=True)\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    cv_scores = {i:[] for i in range(len(clfs))}\n",
    "    cv_scores[\"Avg\"] = []\n",
    "    i = 0\n",
    "    for train_idx, val_idx in skf.split(data, y):\n",
    "        i += 1\n",
    "        X = data.copy()\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        X_train, X_val, feats = coreProcess(X, y_train, train_idx, val_idx)\n",
    "        tmp = []\n",
    "        preds = []\n",
    "        j = 0\n",
    "        for clf in clfs:\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_val_pred = clf.predict_proba(X_val)\n",
    "            tmp.append(y_val_pred)\n",
    "            loss = log_loss(y_val, y_val_pred)\n",
    "            cv_scores[j].append(loss)\n",
    "            preds.append(y_val_pred)\n",
    "            j += 1\n",
    "            print(\"clf_{}, Iteration {}'s loss: {}\".format(j, i, loss))\n",
    "        preds = np.array(preds)\n",
    "        avg_pred = np.mean(preds, axis=0)\n",
    "        loss = log_loss(y_val, avg_pred)\n",
    "        cv_scores[\"Avg\"].append(loss)\n",
    "        print(\"Iteration {}'s Avg loss: {}\".format(i, loss))\n",
    "    for i in range(len(clfs)):\n",
    "        print(\"clf_{} validation loss : {}\".format(i, np.mean(cv_scores[i])))\n",
    "    print(\"Average validation loss : {}\".format(np.mean(cv_scores[\"Avg\"])))\n",
    "    print(\"*** Validation finished ***\\n\")\n",
    "    return cv_scores[\"Avg\"]\n",
    "\n",
    "\n",
    "def paramSearch(clf, param_dict):\n",
    "\n",
    "    def outer_join(left, right):\n",
    "        if left == []:\n",
    "            return right\n",
    "        if right == []:\n",
    "            return left\n",
    "        res = []\n",
    "        for i in left:\n",
    "            for j in right:\n",
    "                if isinstance(i, list):\n",
    "                    tmp = i[:]\n",
    "                    tmp.append(j)\n",
    "                    res.append(tmp)\n",
    "                else:\n",
    "                    res.append([i, j])\n",
    "        return res\n",
    "    # Creating list of param_dict\n",
    "    param_list = sorted(param_dict.items(), key=lambda x: x[0])\n",
    "    param_keys = [ item[0] for item in param_list ]\n",
    "    param_vals = [ item[1] for item in param_list ]\n",
    "    all_vals = []\n",
    "    for val in param_vals:\n",
    "        all_vals = outer_join(all_vals, val)\n",
    "    all_param_lists = []\n",
    "    for vals in all_vals:\n",
    "        all_param_lists.append(dict(zip(param_keys, vals)))\n",
    "    # for item in all_param_lists:\n",
    "    #     print(item)\n",
    "\n",
    "    # Searching\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for params in all_param_lists:\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        for param_name in params.keys():\n",
    "            print(\"{} : {}\".format(param_name, params[param_name]))\n",
    "        clf.set_params(**params)\n",
    "        score = np.mean(validation_score(clf))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "        i += 1\n",
    "        print(\"{} / {}, Done\".format(i, len(all_param_lists)))\n",
    "        print(\"Score: \", score)\n",
    "        scores.append(score)\n",
    "    print(scores)\n",
    "    print(\"Best parameters:\")\n",
    "    for param_name in best_params.keys():\n",
    "        print(\"{} : {}\".format(param_name, best_params[param_name]))\n",
    "    print(\"Score: \", best_score)\n",
    "\n",
    "\n",
    "def gen_sub():\n",
    "    train = train_data.copy()\n",
    "    train_idx = [i for i in range(train.shape[0])]\n",
    "    test = test_data.copy()\n",
    "    test_idx = [i + train.shape[0] for i in range(test.shape[0])]\n",
    "    y = train[\"interest_level\"].apply(lambda x: target_num_map[x])\n",
    "    del train[\"interest_level\"]\n",
    "    data = pd.concat([train, test]).reset_index()\n",
    "    X_train, X_test, feats = coreProcess(data, y, train_idx, test_idx)\n",
    "    xgb_clf = xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 12,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.8,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1700,\n",
    "        seed = RS,\n",
    "    )\n",
    "    print(\"Trainning:...\")\n",
    "    xgb_clf.fit(X_train, y)\n",
    "\n",
    "    preds = xgb_clf.predict_proba(X_test)\n",
    "    sub = pd.DataFrame(preds)\n",
    "    # sub.columns = [\"high\", \"medium\", \"low\"]\n",
    "    sub.columns = [ \"high\", \"medium\", \"low\"]\n",
    "    sub[\"listing_id\"] = test.listing_id.values\n",
    "    sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "\n",
    "def genAvgSub(clfs):\n",
    "    train = train_data.copy()\n",
    "    train_idx = [i for i in range(train.shape[0])]\n",
    "    test = test_data.copy()\n",
    "    test_idx = [i + train.shape[0] for i in range(test.shape[0])]\n",
    "    y = train[\"interest_level\"].apply(lambda x: target_num_map[x])\n",
    "    del train[\"interest_level\"]\n",
    "    data = pd.concat([train, test]).reset_index()\n",
    "    X_train, X_test, feats = coreProcess(data, y, train_idx, test_idx)\n",
    "    print(\"Trainning:...\")\n",
    "    preds = []\n",
    "    for i in range(len(clfs)):\n",
    "        print(\"Clf_{} fiting\".format(i))\n",
    "        clfs[i].fit(X_train, y)\n",
    "        print(\"Clf_{} predicting\".format(i))\n",
    "        pred = clfs[i].predict_proba(X_test)\n",
    "        preds.append(pred)\n",
    "    sub = pd.DataFrame(np.mean(preds, axis=0))\n",
    "    # sub.columns = [\"high\", \"medium\", \"low\"]\n",
    "    sub.columns = [ \"high\", \"medium\", \"low\"]\n",
    "    sub[\"listing_id\"] = test.listing_id.values\n",
    "    sub.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Train done.\")\n",
    "\n",
    "\n",
    "def validate(clfs):\n",
    "    cv_scores = validation_avg_score(clfs)\n",
    "    return cv_scores\n",
    "\n",
    "\n",
    "def search():\n",
    "    param_dict = {\n",
    "        'eta' : [0.02],\n",
    "        'max_depth' : [6],\n",
    "        'subsample' : [0.8],\n",
    "        'colsample_bylevel' : [0.7],\n",
    "        'num_rounds' : [1400, 1500, 1600, 1650],\n",
    "    }\n",
    "    clf = xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 12,\n",
    "        eta = 0.04,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.7,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 1.0,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 700,\n",
    "        seed = RS,\n",
    "    )\n",
    "    paramSearch(clf, param_dict)\n",
    "\n",
    "\n",
    "def write2file(cv_scores, val_desc=None):\n",
    "    print(\"*\" * 50)\n",
    "    print(\"Cross validation loss: \", np.mean(cv_scores))\n",
    "    with open(\"results.log\", \"a\") as fp:\n",
    "        fp.write(time.strftime(\"%m/%d/%Y %H:%M\") + '\\n')\n",
    "        if(val_desc is not None):\n",
    "            fp.write(val_desc + '\\n')\n",
    "        for score in cv_scores:\n",
    "            fp.write(str(score) + \" \")\n",
    "        fp.write(\"\\nCross Validation: {}\\n\".format(np.array(cv_scores).mean()))\n",
    "        fp.write(\"*\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "def stacking(clfs):\n",
    "    print(\"Stacking\")\n",
    "    train = train_data.copy()\n",
    "    test = test_data.copy()\n",
    "    y = train[\"interest_level\"].apply(lambda x: target_num_map[x])\n",
    "    del train[\"interest_level\"]\n",
    "    train_stackers = []\n",
    "    for RS in [0, 1, 2, 64, 128, 256, 512, 1024, 2048, 4096]:\n",
    "        skf = StratifiedKFold(n_splits=10, random_state=RS, shuffle=True)\n",
    "        #Create Arrays for meta\n",
    "        train_stacker = [[0.0 for s in range(3)]  for k in range (0,(train.shape[0]))]\n",
    "        cv_scores = {i:[] for i in range(len(clfs))}\n",
    "        cv_scores[\"Avg\"] = []\n",
    "        print(\"Begin 10-flod cross validation\")\n",
    "        cnt = 0\n",
    "        for train_idx, val_idx in skf.split(train, y):\n",
    "            cnt += 1\n",
    "            X = train.copy()\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            X_train, X_val, feats = coreProcess(X, y_train, train_idx, val_idx)\n",
    "            X_train.toarray()\n",
    "            preds = []\n",
    "            k = 0\n",
    "            for clf in clfs:\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_val_pred = clf.predict_proba(X_val)\n",
    "                loss = log_loss(y_val, y_val_pred)\n",
    "                preds.append(y_val_pred)\n",
    "                cv_scores[k].append(loss)\n",
    "                k += 1\n",
    "                print(\"Clf_{} iteration {}'s loss: {}\".format(k, cnt, loss))\n",
    "            preds = np.array(preds)\n",
    "            avg_pred = np.mean(preds, axis=0)\n",
    "            avg_loss = log_loss(y_val, avg_pred)\n",
    "            cv_scores[\"Avg\"].append(avg_loss)\n",
    "            print(\"Iteration {}'s Avg loss: {}\".format(cnt, avg_loss))\n",
    "            no = 0\n",
    "            for real_idx in val_idx:\n",
    "                for i in range(3):\n",
    "                    train_stacker[real_idx][i] = avg_pred[no][i]\n",
    "                no += 1\n",
    "        for i in range(len(clfs)):\n",
    "            print(\"clf_{} validation loss : {}\".format(i, np.mean(cv_scores[i])))\n",
    "        print(\"Average validation loss : {}\".format(np.mean(cv_scores[\"Avg\"])))\n",
    "        train_stackers.append(train_stacker)\n",
    "    train_stacker = np.mean(train_stackers, axis=0)\n",
    "    print(\"*** Validation finished ***\\n\")\n",
    "\n",
    "    test_stacker = [[0.0 for s in range(3)]   for k in range (0,(test.shape[0]))]\n",
    "    train_idx = [i for i in range(train.shape[0])]\n",
    "    test_idx = [i + train.shape[0] for i in range(test.shape[0])]\n",
    "    data = pd.concat([train, test]).reset_index()\n",
    "    X_train, X_test, feats = coreProcess(data, y, train_idx, test_idx)\n",
    "    print(X_train.shape, len(train_stacker))\n",
    "    print(\"Begin predicting\")\n",
    "    preds = []\n",
    "    for i in range(len(clfs)):\n",
    "        print(\"Clf_{} fiting\".format(i))\n",
    "        clfs[i].fit(X_train, y)\n",
    "        print(\"Clf_{} predicting\".format(i))\n",
    "        pred = clfs[i].predict_proba(X_test)\n",
    "        preds.append(pred)\n",
    "    preds = np.mean(preds, axis=0)\n",
    "    for pr in range (0, len(preds)):  \n",
    "            for d in range (0,3):            \n",
    "                test_stacker[pr][d]=(preds[pr][d])   \n",
    "    print (\"merging columns\")   \n",
    "    #stack xgboost predictions\n",
    "    X_train = np.column_stack((X_train.toarray(),train_stacker))\n",
    "    # stack id to test\n",
    "    X_test = np.column_stack((X_test.toarray(),test_stacker))         \n",
    "    # stack target to train\n",
    "    X = np.column_stack((y,X_train))\n",
    "    ids = test.listing_id.values\n",
    "    X_test = np.column_stack((ids, X_test))\n",
    "    np.savetxt(\"./train_stacknet.csv\", X, delimiter=\",\", fmt='%.5f')\n",
    "    np.savetxt(\"./test_stacknet.csv\", X_test, delimiter=\",\", fmt='%.5f') \n",
    "    print(\"Write results...\")\n",
    "    output_file = \"submission_{}.csv\".format(np.mean(cv_scores[\"Avg\"]))\n",
    "    print(\"Writing submission to %s\" % output_file)\n",
    "    f = open(output_file, \"w\")   \n",
    "    f.write(\"listing_id,high,medium,low\\n\")# the header   \n",
    "    for g in range(0, len(test_stacker))  :\n",
    "      f.write(\"%s\" % (ids[g]))\n",
    "      for prediction in test_stacker[g]:\n",
    "         f.write(\",%f\" % (prediction))    \n",
    "      f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clfs = []\n",
    "    # clfs.append(xgboostClassifier(\n",
    "    #     objective = 'multi:softprob',\n",
    "    #     eval_metric = 'mlogloss',\n",
    "    #     num_class = 3,\n",
    "    #     nthread = 6,\n",
    "    #     eta = 0.04,\n",
    "    #     max_depth = 6,\n",
    "    #     subsample = 0.7,\n",
    "    #     colsample_bytree = 1.0,\n",
    "    #     colsample_bylevel = 0.7,\n",
    "    #     min_child_weight=1,\n",
    "    #     silent = 1,\n",
    "    #     num_rounds = 700,\n",
    "    #     seed = 0,\n",
    "    # ))\n",
    "    # clfs.append(xgboostClassifier(\n",
    "    #     objective = 'multi:softprob',\n",
    "    #     eval_metric = 'mlogloss',\n",
    "    #     num_class = 3,\n",
    "    #     nthread = 6,\n",
    "    #     eta = 0.02,\n",
    "    #     max_depth = 6,\n",
    "    #     subsample = 0.8,\n",
    "    #     colsample_bytree = 1.0,\n",
    "    #     colsample_bylevel = 0.8,\n",
    "    #     min_child_weight=1,\n",
    "    #     silent = 1,\n",
    "    #     num_rounds = 1700,\n",
    "    #     seed = 0,\n",
    "    # ))\n",
    "    clfs.append(xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 9,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.7,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1500,\n",
    "        seed = 0,\n",
    "    ))\n",
    "    clfs.append(xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 9,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.8,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1500,\n",
    "        seed = 128,\n",
    "    ))\n",
    "    clfs.append(xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 9,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.8,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1500,\n",
    "        seed = 512,\n",
    "    )) \n",
    "    clfs.append(xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 9,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.8,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1500,\n",
    "        seed = 1024,\n",
    "    ))   \n",
    "    clfs.append(xgboostClassifier(\n",
    "        objective = 'multi:softprob',\n",
    "        eval_metric = 'mlogloss',\n",
    "        num_class = 3,\n",
    "        nthread = 9,\n",
    "        eta = 0.02,\n",
    "        max_depth = 6,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 1.0,\n",
    "        colsample_bylevel = 0.8,\n",
    "        min_child_weight=1,\n",
    "        silent = 1,\n",
    "        num_rounds = 1500,\n",
    "        seed = 2048,\n",
    "    ))    \n",
    "    if len(sys.argv) == 1:\n",
    "        cv_scores = validate(clfs)\n",
    "        write2file(cv_scores)\n",
    "    elif len(sys.argv) == 2:\n",
    "        if sys.argv[1] == '-v':\n",
    "            cv_scores = validate(clfs)\n",
    "            write2file(cv_scores)\n",
    "        elif sys.argv[1] == '-g':\n",
    "            gen_sub()\n",
    "        elif sys.argv[1] == '-s':\n",
    "            search()\n",
    "        elif sys.argv[1] == '-ga':\n",
    "            genAvgSub(clfs)\n",
    "        elif sys.argv[1] == '-stack':\n",
    "            stacking(clfs)\n",
    "        elif sys.argv[1] == '-v3':\n",
    "            cv_scores = validate(clfs)\n",
    "            val_desc = sys.argv[2]\n",
    "            write2file(cv_scores, val_desc)\n",
    "    elif len(sys.argv) == 3:\n",
    "        if sys.argv[1] == '-v':\n",
    "            cv_scores = validate(clfs)\n",
    "            val_desc = sys.argv[2]\n",
    "            write2file(cv_scores, val_desc)\n",
    "        elif sys.argv[1] == '-g':\n",
    "            gen_sub()\n",
    "        elif sys.argv[1] == '-v3':\n",
    "            cv_scores = validation_score()\n",
    "            val_desc = sys.argv[2]\n",
    "            write2file(cv_scores, val_desc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
